# Roadmap: IT-Start Bot / Core API

Пошаговый план от инициализации до продукта, полностью соответствующего ТЗ, user stories и уставу. Чекбоксы отражают текущий статус; отмеченные задачи уже реализованы в кодовой базе на 2025-12-12.

## Этап 0. Базовая инфраструктура и каркас
- [x] Скелет монорепо (FastAPI + aiogram 3 + общий доменный слой).
- [x] Базовые миграции, схемы БД и enum’ы синхронизированы с ТЗ.
- [x] Docker-compose (db, redis, core-api, tg-bot), env-конфигурация.
- [x] CI/CD заготовка: линтеры (black, isort, ruff), mypy, pytest, coverage.
- [x] Подключить Celery worker + beat как отдельные сервисы в docker-compose.
- [x] Настроить автоматический запуск Alembic миграций при деплое.

## Этап 1. Доменные модели и данные
- [x] SQLAlchemy модели и репозитории для публикаций, тегов, пользователей бота, подписок, предпочтений, парсеров, результатов парсинга, админов, расписаний.
- [x] Pydantic-схемы (read) и тесты на них.
 - [x] Обновить `docs/db_schemes.sql` под актуальные миграции (status, decline_reason, contact_info, schedule, audit, deadline_notified, user_preferences, parser поля).
- [x] Добавить типы публикаций/событий из устава (contests/hackathons) — приоритезировать после согласования.

## Этап 2. Аутентификация и безопасность
- [x] JWT login/refresh, Argon2 пароли, rate-limit логина, white-list IP.
- [x] TOTP 2FA, запрет отключения для admin.
- [ ] Централизованный VPN/IP enforcement (прокси/ingress уровень) + док.
- [x] Распределённый rate-limit (Redis) вместо in-memory.
- [ ] Регулярный аудит прав и ролей (admin/moderator) и логов действий по всем CRUD.

## Этап 3. Админка (Core API)
- [x] Admin users: list/create/patch/disable + аудит.
- [x] Tags CRUD + сидинг базовых значений по категориям.
- [x] Publications: list/get/patch(status/title/description/contact_info/deadline), decline, approve.
- [x] Добавить создание/удаление публикаций в API, валидация уникальности/дедуп.
- [x] `approve-and-send` должен реально инициировать рассылку (канал + подписчики) с пометкой [UPD] для изменённых записей.
 - [x] Отображение editor_id и статусов модерации в ответах/фронте.
- [x] Parsers CRUD/enable/disable.
- [x] Хранение результатов парсинга в `parsing_result` (success/received/timestamp/parser_id) + `last_parsed_at`.
- [ ] Хранение текста ошибок/trace для падений парсеров (сейчас ошибки только в логах/Sentry).
- [x] Publication schedule CRUD (таблица schedule).
- [x] Связать schedule с планировщиком (Celery beat) и cron-интервалами (без рестартов).
- [x] Stats: пользователи, топ-5 тегов, ошибки парсеров, публикации по дням.
- [x] Export CSV/XLSX публикаций за период.
- [ ] Экспорт в Google Sheets (устав).

## Этап 3b. Админка (Frontend React)
- [x] Auth/refresh/2FA, смена пароля, защита роутов по ролям.
- [x] Пользователи админки: список/создание/редактирование/блокировка (role-based UI).
- [x] Теги: CRUD + фильтры по категориям.
- [x] Публикации: список/деталь, фильтры, редактирование, decline, approve-and-send, экспорт CSV/XLSX.
- [x] Источники (парсеры): список/создание/редактирование/enable/disable.
- [x] Статистика, расписание рассылок, health/метрики страницы.
- [x] UI для создания/удаления публикаций, подсветка дублей/валидность URL, отображение editor_id и статусов модерации/[UPD].
- [ ] Отображение результатов парсеров и ошибок; индикаторы последнего запуска.
- [ ] Интеграция Google Sheets экспорта (кнопка/статус) после реализации в API.

## Этап 4. Парсеры
- [x] Реализовать модуль запуска парсеров (external executable) с конфигом из БД.
- [x] Повторные попытки 15/45 мин при ошибках; логгирование в Sentry.
- [x] Авто-дедуп: URL + (title + company + дата) — soft блокировка дублей.
- [x] Авто-тегирование по словарю тегов из БД (поиск подстрок; морфология опционально).
- [ ] Минимум 5 источников (сейчас в репозитории 4: tbank/vk/nastachku/podlodka).
- [x] Протоколировать в `parsing_result` (success, count, timestamp, parser_id).
- [x] Скрипты парсеров находятся в `parsers/` и интегрированы в запуск через Celery (`run_parsers`).
- [x] Парсеры упакованы в Docker-образ `Dockerfile.core` и запускаются через `celery-worker`/`celery-beat` в `docker-compose`.

## Этап 5. Телеграм-бот
- [x] Команды /start, /help, /subscribe, /unsubscribe, /preferences, /jobs, /internships, /conferences.
- [x] FSM для поэтапной подписки/отписки; проверки occupation/platform/language для jobs/internships.
- [x] Кэш поиска в Redis; обработка блокировки (my_chat_member) с очисткой данных.
- [ ] Хранить FSM в Redis (Memory → Redis storage) для отказоустойчивости.
- [ ] Инлайн-кнопки для всех основных команд + /settings для включения/выключения напоминаний.
- [x] Поддержка новых типов (contests/hackathons) и локализация подсказок.
- [ ] Канальный постинг [UPD] при редактировании ранее отправленных публикаций.

## Этап 6. Рассылки и уведомления
- [x] Celery задачи: рассылка новых публикаций, дедлайны (3 дня), cleanup >90 дней.
- [x] Подключить Celery beat расписания: публикации по `publication_schedule`, дедлайны раз в сутки, cleanup раз в сутки.
- [ ] Персональные напоминания: уважать флаг `deadline_reminder` в подписке, дать управление из бота (/settings) и админки.

## Этап 7. Мониторинг, логирование, резервирование
- [x] Sentry для API/бота; Prometheus /metrics.
- [ ] Sentry для Celery/парсеров; отдельный тег сервиса в событиях.
- [ ] Grafana дашборд (метрики: req rate/latency, celery queue, парсеры, ошибки).
- [ ] Резервные копии БД (ежедневно, хранение 3 месяца) + восстановление по регламенту.
- [ ] Уведомления о критических ошибках в TG-группу разработчиков.

## Этап 8. Производительность и масштабирование
- [ ] Нагрузочное тестирование: 5000+ одновременных пользователей, отклик <1s.
- [ ] Профилирование длительных операций (поиск, рассылка) и кеширование горячих выборок.
- [ ] Горизонтальное масштабирование бота (webhook/polling) и API (uvicorn workers, DB pool).

## Этап 9. Качество и тестирование
- [x] Модульные/интеграционные тесты (ORM, репозитории, API, бот-сервис, Celery задачи, безопасность, rate-limit, healthz, metrics).
- [ ] E2E: сценарий “парсинг → модерация → рассылка → дедлайн напоминание → отписка”.
- [ ] Контрактные тесты для парсеров (стаб источников).
- [ ] Тесты на экспорт (CSV/XLSX/Sheets) и на расписания.
- [ ] Регулярные отчёты coverage >=80% доменной логики.

## Этап 10. Документация и ввод в эксплуатацию
- [ ] Обновить README/architecture/TЗ с фактами реализации (сервисы, порты, переменные окружения, расписания).
- [ ] Описать playbook деплоя и восстановления из бэкапа.
- [ ] Пользовательская документация админки и бота (команды, фильтры, ограничения).
- [ ] Провести приемочное тестирование по user stories и критериям устава; подписать акт.

## Рекомендованный порядок исполнения спринтов (2-недели)
1. Домен/модерация: обновить db_schemes.sql, добавить contests/hackathons, включить create/delete публикаций + dedup, починить approve-and-send с реальной рассылкой и [UPD], отобразить editor_id/статусы в API+UI.
2. Парсеры: модуль запуска + ретраи + логирование в Sentry, протоколирование parsing_result, авто-дедуп/авто-тегирование, интеграция скриптов из `docs/Парсеры.zip`, Docker сервисы; минимум 2–3 источника.
3. UX рассылок: FSM бота в Redis, инлайн-меню + /settings для флага deadline_reminder, поддержка contests/hackathons, канал [UPD] при правках; персональные напоминания.
4. Мониторинг и надёжность: Sentry для Celery/парсеров, Grafana дашборды, алерты в TG, ежедневные бэкапы БД + регламент восстановления; экспорт Google Sheets (API+UI).
5. Расширение парсеров до 5+ источников, оптимизация производительности/кешей, профилирование.
6. Нагрузочные/E2E сценарии “парсинг → модерация → рассылка → дедлайн → отписка”, контрактные тесты парсеров, финализация документации и приемка по user stories/уставу.
